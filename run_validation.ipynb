{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1049bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from transformers import pipeline\n",
    "from contextlib import contextmanager\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def use_model(model_id, task=\"automatic-speech-recognition\", **kwargs):\n",
    "    # Login to HF\n",
    "    try:\n",
    "        with open(\"hf_key.txt\", \"r\") as f:\n",
    "            key = f.read().strip()\n",
    "            login(token=key)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No HF hub key detected, proceeding without one\")\n",
    "\n",
    "    print(f\"--- Loading: {model_id} ---\")\n",
    "     \n",
    "    is_whisper = \"whisper\" in model_id\n",
    "\n",
    "    \n",
    "    pipe = pipeline(\n",
    "                    task, # type: ignore  \n",
    "                    model=model_id,\n",
    "                    dtype=torch.float16,\n",
    "                    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "                    chunk_length_s=30 if is_whisper else None,\n",
    "                )   \n",
    "    \n",
    "    try:\n",
    "        yield pipe\n",
    "    finally:\n",
    "        # Cleanup VRAM\n",
    "        print(f\"--- Cleaning up: {model_id} ---\")\n",
    "        del pipe\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav2vec = \"facebook/wav2vec2-lv-60-espeak-cv-ft\"\n",
    "whisper_turbo = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "with use_model(wav2vec) as pipe:\n",
    "    # Pass generation parameters here rather than in the pipeline constructor\n",
    "    result = pipe(\n",
    "        \"data/scope_phoneme_data/A long/A long 1.wav\",\n",
    "        generate_kwargs={\n",
    "            \"language\": \"en\", \n",
    "            \"task\": \"transcribe\",\n",
    "            \"return_timestamps\": 'char'\n",
    "        }\n",
    "    )\n",
    "    print(result[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
