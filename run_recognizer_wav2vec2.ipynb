{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5870e4ff902a4fe9ace5cadb3a821ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/424 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phonemized Output: ɑ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "model_id = \"facebook/wav2vec2-lv-60-espeak-cv-ft\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonemize_audio(audio_path):\n",
    "    speech, sr = librosa.load(audio_path, sr=16000) # resamples to 16,000Hz\n",
    "    input_values = processor(speech, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    phonemes = processor.batch_decode(predicted_ids)\n",
    "    return phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: scope_phoneme_data/test\n",
      "--- Recording started for 3 seconds ---\n",
      "--- Recording finished ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'scope_phoneme_data/test/test_record.wav'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def record_audio(filename, duration=3, sample_rate=16000):\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "\n",
    "    print(f\"--- Recording started for {duration} seconds ---\")\n",
    "    \n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    \n",
    "    sd.wait()\n",
    "    \n",
    "    print(\"--- Recording finished ---\")\n",
    "    \n",
    "    write(filename, sample_rate, recording)\n",
    "    return filename\n",
    "\n",
    "# record_audio(\"scope_phoneme_data/test/test_record.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record & Run Recognizer Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recording started for 3 seconds ---\n",
      "--- Recording finished ---\n",
      "['aː s s d']\n"
     ]
    }
   ],
   "source": [
    "file_name = \"scope_phoneme_data/test/test_record.wav\"\n",
    "record_audio(file_name)\n",
    "print(phonemize_audio(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Recognizer for all SCOPE Phoneme Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Folder/Label     File Name Predicted Phonemes\n",
      "0       O long  O long 4.wav                [ɑ]\n",
      "1       O long  O long 1.wav                [ɑ]\n",
      "2       O long  O long 3.wav                [ɑ]\n",
      "3       O long  O long 2.wav                [ɑ]\n",
      "4            J       J 3.wav             [tʃ ɑ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"data/scope_phoneme_data\"\n",
    "data_records = []\n",
    "\n",
    "for folder_name in os.listdir(data_path):\n",
    "    folder_path = os.path.join(data_path, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                phonemes = phonemize_audio(file_path)\n",
    "                \n",
    "                data_records.append({\n",
    "                    \"Folder/Label\": folder_name,\n",
    "                    \"File Name\": file_name,\n",
    "                    \"Predicted Phonemes\": phonemes\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(data_records)\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"phoneme_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
